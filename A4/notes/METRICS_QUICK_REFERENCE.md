# Classification Metrics - Quick Reference Card

## ğŸ¯ The 4 Core Metrics (for NSP)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Metric    â”‚     What It Asks         â”‚   Formula   â”‚  Your Score  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PRECISION   â”‚ When I say "Yes",        â”‚ TP/(TP+FP)  â”‚    50%       â”‚
â”‚             â”‚ am I usually right?      â”‚             â”‚  (random)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RECALL      â”‚ Of all "Yes" cases,      â”‚ TP/(TP+FN)  â”‚    50%       â”‚
â”‚             â”‚ how many did I catch?    â”‚             â”‚  (random)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ F1-SCORE    â”‚ What's the balance       â”‚ 2Ã—PÃ—R/(P+R) â”‚    50%       â”‚
â”‚             â”‚ between Prec & Recall?   â”‚             â”‚  (random)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SUPPORT     â”‚ How many samples         â”‚ Count       â”‚  150 each    â”‚
â”‚             â”‚ in this class?           â”‚             â”‚  (balanced)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”¢ Confusion Matrix (NSP)

```
                    PREDICTED
                Not Next   Is Next
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    ACTUAL    â”‚          â”‚         â”‚
    Not Next  â”‚   TN     â”‚   FP    â”‚  â† False Positive = Said "Yes" but was "No"
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    Is Next   â”‚   FN     â”‚   TP    â”‚  â† False Negative = Said "No" but was "Yes"
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†‘
          False Negative
```

**Your Model:**
```
              Not Next   Is Next
    Not Next     75        75      â† 50% accuracy (like flipping coin)
    Is Next      75        75      â† 50% accuracy (like flipping coin)
```

## ğŸ“ Formulas with Visual Breakdown

### Precision
```
          TP                     Correct "Is Next" predictions
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  =  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      TP + FP           All times you predicted "Is Next"

    "When I say 'Is Next', how often am I right?"
```

### Recall
```
          TP                     Correct "Is Next" predictions
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  =  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      TP + FN          All actual "Is Next" in the dataset

    "Of all real 'Is Next', how many did I find?"
```

### F1-Score
```
         2 Ã— Precision Ã— Recall
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Precision + Recall

    "Harmonic mean - punishes imbalance!"
```

## ğŸ“Š When to Use Each Metric

| Situation | Best Metric | Why |
|-----------|-------------|-----|
| **Balanced classes** (50/50 split) | Accuracy or F1 | Both reliable |
| **Imbalanced classes** (95/5 split) | F1-Score, Precision, Recall | Accuracy misleading! |
| **False positives costly** (spam filter) | Precision | Don't mark good emails as spam |
| **False negatives costly** (cancer test) | Recall | Don't miss sick patients |
| **Both errors matter equally** | F1-Score | Best overall balance |

## ğŸ­ NSP vs MLM Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NSP (Next Sentence Prediction)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ 2 classes (Not Next, Is Next)                         â”‚
â”‚  â€¢ Use: Accuracy, Precision, Recall, F1, Confusion Mx    â”‚
â”‚  â€¢ Your score: 50% (random guessing)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLM (Masked Language Modeling)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ ~520,000 classes (every word)                         â”‚
â”‚  â€¢ Use: Accuracy, Perplexity                             â”‚
â”‚  â€¢ Your score: 4.34% accuracy, perplexity = 1.3M (bad)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš¦ Score Interpretation

```
Score        NSP Performance    What It Means
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
100%         ğŸŸ¢ Perfect         Impossible in practice
90-99%       ğŸŸ¢ Excellent       State-of-the-art models
80-89%       ğŸŸ¢ Good            Well-trained model
70-79%       ğŸŸ¡ Fair            Needs improvement
60-69%       ğŸŸ¡ Poor            Undertrained
50-59%       ğŸ”´ Very Poor       Barely better than random
50%          ğŸ”´ Random          Your current model! â† Need more training
<50%         ğŸ”´ Worse than random  Something is broken
```

## ğŸ’¡ Real-World Analogies

### Precision
```
ğŸ¯ Archery: Of the arrows that hit the target, how many hit the bullseye?
   High Precision = Tight grouping (even if off-center)
```

### Recall
```
ğŸ£ Fishing: Of all the fish in the pond, how many did you catch?
   High Recall = Caught most fish (even if you caught some boots too)
```

### F1-Score
```
âš–ï¸  Balance: Good at both aiming (precision) AND catching (recall)
   High F1 = Tight grouping near bullseye AND caught most fish
```

## ğŸ”§ How to Use 

```python
from sklearn.metrics import classification_report

# For NSP evaluation
print(classification_report(
    y_true=nsp_labels,           # Actual labels
    y_pred=nsp_predictions,      # Model predictions
    target_names=['Not Next', 'Is Next']
))

# Output will show:
#              precision    recall  f1-score   support
#   Not Next       0.50      0.50      0.50       150
#     Is Next       0.50      0.50      0.50       150
```

## ğŸ“ Summary Cheat Sheet

```
When someone asks:                  Answer with:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"How good is your model?"           â†’ Accuracy or F1-Score
"How trustworthy are positives?"    â†’ Precision
"How many positives did you find?"  â†’ Recall
"What's the balance?"               â†’ F1-Score
"How many samples per class?"       â†’ Support
"Show me the errors"                â†’ Confusion Matrix
```

## ğŸš€ Improving Your BERT Model

Your current scores (NSP: 50%, MLM: 4%) mean you need:

1. âœ… **More training data** - Use 10k-100k samples, not tiny batches
2. âœ… **More epochs** - Train for 1000+ epochs
3. âœ… **Smaller vocabulary** - Use WordPiece (30k words) not raw words (520k)
4. âœ… **Better tokenization** - Use BertTokenizer from HuggingFace
5. âœ… **Learning rate scheduling** - Add warmup and decay

**Goal Metrics:**
- NSP Accuracy: >85%
- NSP F1-Score: >85%
- MLM Accuracy: >60%
- MLM Perplexity: <20

---

## ğŸ“š Resources in This Folder

1. **classification_metrics_explained.md** - Detailed explanations with examples
2. **metrics_examples.py** - Interactive Python examples
3. **bert_evaluation_metrics.py** - Complete evaluation code for your BERT

**To run examples in notebook:**
```python
%run metrics_examples.py
# Or
from metrics_examples import run_all_examples
run_all_examples()
```

---

*Remember: 50% = coin flip. Your model needs training! ğŸ²*
