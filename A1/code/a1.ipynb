{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd98fb3",
   "metadata": {},
   "source": [
    "# A1: That’s What I LIKE\n",
    "\n",
    "Class: AT82.05 Artificial Intelligence: Natural Language Understanding (NLU) \n",
    "\n",
    "Taught by: Dr. Chaklam Silpasuwanchai, Todsavad Tangtortan\n",
    "\n",
    "Semester: Jan 2026\n",
    "\n",
    "\n",
    "This assignment focuses on creating a system to find similar context in Natural Language Processing. \n",
    "\n",
    "The system, deployed on a website, should return the top paragraphs with the most similar context to a given query, such as ”Harry Potter.” \n",
    "\n",
    "This task will involve building upon existing code, understanding and implementing word **embedding techniques**, and creating a web interface for the system to deliver the results.\n",
    "\n",
    "**Deliverables:**\n",
    "\n",
    "1) The GitHub link containing the jupyter notebook, \n",
    "2) a README.md of the github, \n",
    "3) and the folder of your web application called ‘app’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a88ee8",
   "metadata": {},
   "source": [
    "# Task 1. Preparation and Training\n",
    "\n",
    "Build upon the code discussed in class. Do not use pre-built solutions from the internet.\n",
    "\n",
    "## 1) Read and understand the Word2Vec1 and GloVe2 papers.\n",
    "\n",
    "- [Word2Vec1](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "\n",
    "- [GloVe2](https://aclanthology.org/D14-1162.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25b146",
   "metadata": {},
   "source": [
    "## 2) Modify the Word2Vec (with & without negative sampling) and GloVe from the lab lecture (3 points)\n",
    "\n",
    "- Train using a real-world corpus (suggest to categories news from nltk datset). \n",
    "\n",
    ">> Refer https://www.nltk.org/data.html \n",
    "\n",
    "Python interactive code:\n",
    "\n",
    "```python\n",
    "    import nltk\n",
    "    nltk.download() # this will download ALL NLTK data, it will take forever!\n",
    "    # define corpus\n",
    "    nltk.download('reuters') # download corpus from reuters\n",
    "    # If you do not provide any location to download, it will download in homedirectory \n",
    "    # eg. ~/nlkt_data/brown.zip\n",
    "```\n",
    "\n",
    "\n",
    "- Ensure to source this dataset from reputable public databases or repositories. It is imperative to give proper credit to the dataset source in your documentation.\n",
    "\n",
    ">> Refer https://www.nltk.org/howto/corpus.html\n",
    "\n",
    "As per suggestion, this assignment will use fetch_20newsgroups for news data\n",
    "\n",
    "\n",
    "- Create a function that allows dynamic modification of the window size during training. Use a window size of 2 as default\n",
    "\n",
    "\n",
    "### Steps followed:\n",
    "1. Download the 20 Newsgroups dataset from NLTK\n",
    "2. Preprocess the articles (tokenize, clean)\n",
    "3. Train your Word2Vec and GloVe models on this corpus\n",
    "4. Document where the dataset came from (give proper credit in README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac06d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numerical computations\n",
    "import numpy as np\n",
    "# neural network libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0bafd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.4.1', '2.9.1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec1a1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a9136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom data folder\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "data_folder = Path(notebook_dir).parent / \"data\"\n",
    "data_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081506f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-npl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
