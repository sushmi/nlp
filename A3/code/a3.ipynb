{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f647871",
   "metadata": {},
   "source": [
    "# A3: Make Your Own Machine Translation \n",
    "\n",
    "In this assignment, we will explore the domain of neural machine translation. The focus will be on\n",
    "translating between your native language and English. We will experiment with different types of attention\n",
    "mechanisms, including general attention, multiplicative attention, and additive attention, to evaluate their\n",
    "effectiveness in the translation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0491c",
   "metadata": {},
   "source": [
    "#### Step 0: Prepare Environment - Import Libraries and select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ac4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import datasets, math, re, random, time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1840dc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mimimum required torch version for MPS support \"1.12+\"\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c605dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# universal device selection: use gpu if available, else cpu\n",
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")      # NVIDIA GPU\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")       # Apple Silicon GPU\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# CPU preferred, as MPS keeps on crashing during training with memory errors.\n",
    "#RuntimeError: MPS backend out of memory (MPS allocated: 86.95 GiB, \n",
    "# other allocations: 1.14 GiB, max allowed: 88.13 GiB). Tried to allocate 42.25 MiB on private pool. \n",
    "# Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b656b",
   "metadata": {},
   "source": [
    "## Task 1. Get Language Pair - Based on MT + Transformer.ipynb, modify the dataset as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87b5b5",
   "metadata": {},
   "source": [
    "### 1.1) Find a dataset suitable for translation between your native language and English. Ensure to source this dataset from reputable public databases or repositories. It is imperative to give proper credit to the dataset source in your documentation. (1 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e49d4b",
   "metadata": {},
   "source": [
    "Context Behind Nepali Language:\n",
    "\n",
    "My native language is Nepali. It is spoken by roughly 32 million people around the world as first or second language. \n",
    "Percentage estimate is ~0.4% (total estimated world population 8 Billion people).\n",
    "\n",
    "There's few coproa exists on Nepali to English translation on Hugging Face.\n",
    "1. Opus project [Helsinki NLP Research](https://huggingface.co/datasets/Helsinki-NLP/opus-100/viewer/en-ne)\n",
    "\n",
    "Helsinki-NLP refers to the language technology research group at the University of Helsinki. Here, we publish various resource related to multilingual NLP, machine translation, text simplification to name a few application areas. We focus on wide language coverage, open data sets and public pre-trained models.\n",
    "\n",
    "2. [IRIIS project](https://huggingface.co/IRIIS-RESEARCH)\n",
    "IRIIS-Research is a research group that publishes large-scale raw text corpora on Hugging Face, including one of the largest publicly available Nepali text datasets. This is monolingual Nepali text and large dataset in GBs (~10 GB). \n",
    "\n",
    "3. [ERLA](https://catalog.elra.info/en-us/repository/search/?q=nepali)\n",
    "\n",
    "Founded in 1995, ELRA, the ELRA Language Resources Association is a non-profit organisation whose main mission is to make Language Resources (LRs) for Human Language Technologies (HLT) available to the community at large.\n",
    "\n",
    "4. [FLORES+](https://huggingface.co/datasets/openlanguagedata/flores_plus)\n",
    "FLORES+ is a multilingual machine translation benchmark released under CC BY-SA 4.0. This dataset was originally released by FAIR researchers at Meta under the name FLORES. Further information about these initial releases can be found in Dataset Sources below. The data is now being managed by OLDI, the Open Language Data Initiative. The + has been added to the name to disambiguate between the original datasets and this new actively developed version.\n",
    "\n",
    "Archived Flores : [Flores 200](https://huggingface.co/datasets/facebook/flores/blob/main/README.md#dataset-card-for-flores-200)\n",
    "\n",
    "More on research paper [Natural language processing for Nepali text: a review](../resources/Shahi-Sitaula2021_Article_NaturalLanguageProcessingForNe.pdf)\n",
    "\n",
    "<strong>For the assignment purpose, I am using smaller dataset from hugging face OPUS-100</strong>\n",
    "\n",
    "Opus chosen for:\n",
    "1. Better quality\n",
    "2. Proper train/val/test split\n",
    "3. Managable size with subset\n",
    "4. More realistic results\n",
    "\n",
    "** Tatoeba dataset is smaller good for fast training but it has simple sentences, and may not generalize well.\n",
    "\n",
    "\n",
    "| Dataset     | Size                | Languages      | Use Case                | Quality                  |\n",
    "|-------------|---------------------|----------------|-------------------------|--------------------------|\n",
    "| WMT14       | ~4.5M pairs (de-en) | 2-6 pairs      | Training                | High (news)              |\n",
    "| WMT16       | ~4.5M pairs         | 6-8 pairs      | Training                | High (news)              |\n",
    "| WMT19       | ~38M pairs (de-en)  | 10+ pairs      | Training                | High (news)              |\n",
    "| OPUS-100    | ~55M total          | 100 languages  | Multilingual training   | Medium                   |\n",
    "| Tatoeba     | ~10M total          | 400+ languages | Evaluation/Small training| Medium (user-contributed)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911ceb7",
   "metadata": {},
   "source": [
    "#### Step 1: Data preparation - using OPUS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e0c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation Language Pair: en-ne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "_EN_LANGUAGE = 'en'\n",
    "_NE_LANGUAGE = 'ne'\n",
    "# Use \"de-en\" as dataset doesn't have en-de and treat English as source, German as target.\n",
    "_LANG_PAIR = f\"{_EN_LANGUAGE}-{_NE_LANGUAGE}\"\n",
    "print(\"Translation Language Pair:\", _LANG_PAIR)\n",
    "\n",
    "dataset = load_dataset(\"opus100\", _LANG_PAIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb26ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 406381\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94317c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'The following item is due:',\n",
       "  'ne': 'निम्न वस्तुको म्याद समाप्त हुन्छ:'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde4dcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20000, Val: 2000, Test: 2000\n"
     ]
    }
   ],
   "source": [
    "_TRAIN_SAMPLE_SIZE = 20_000  #100_000\n",
    "# Selecting smaller subsets for faster training/testing\n",
    "train = dataset[\"train\"].select(range(_TRAIN_SAMPLE_SIZE))  # 100K samples\n",
    "val = dataset[\"validation\"]\n",
    "test = dataset[\"test\"]\n",
    "\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b585582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'translation': {'en': '_Inv', 'ne': 'Inv'}},\n",
       " {'translation': {'en': '%1: the message is displayed silently.',\n",
       "   'ne': '% 1: सन्देश ध्वनि बिना प्रदर्शित हुन्छ ।'}},\n",
       " {'translation': {'en': 'Delete Thread', 'ne': 'थ्रेड मेट्नुहोस्'}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0], val[0], test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106dfac7",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2) Describe in detail the process of preparing the dataset for use in your translation model. This includes steps like text normalization, tokenization, and word segmentation, particularly focusing on your native language’s specific requirements. Specify the libraries or tools you will use for these tasks and give appropriate credit to the developers or organizations behind these tools. If your native language requires special handling in tokenization (e.g., for languages like Chinese, Thai, or Japanese), mention the libraries (like Jieba, PyThaiNLP, or Mecab) and the procedures used for word segmentation. (1 points)\n",
    "\n",
    "Note: proper attribution for both the dataset and the tools used in its processing is essential for maintaining\n",
    "academic integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d82727",
   "metadata": {},
   "source": [
    "#### Step 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549fcda0",
   "metadata": {},
   "source": [
    "\n",
    "For English tokenization , pretarined model is used:\n",
    "\n",
    "```bash\n",
    "uv add spacy\n",
    "uv add pip\n",
    "\n",
    "uv run python3 -m spacy download en_core_web_sm \n",
    "```\n",
    "\n",
    "Instead of downloading using uv python, using python script download and save to local.\n",
    "\n",
    "There's no spaCy model for Nepali. For tokenization, \n",
    "\n",
    "1. use tokenizing algorithm and train on data \n",
    "    \n",
    "    Pros: Customized according to data, handles OOV\n",
    "    \n",
    "    Cons: Need to train\n",
    "\n",
    "\n",
    "SentencePiece is a tokenization algorithm (BPE or unigram) - it's simpler and faster.\n",
    "\n",
    "2. Use pretrained tokenizer\n",
    "    \n",
    "    Pros: Ready to use\n",
    "\n",
    "    Cons: May not fit to dataset used\n",
    "\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Already trained, supports Nepali!\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "```\n",
    "\n",
    "Using pre-trained model from Meta [NLLB](https://github.com/facebookresearch/fairseq/tree/nllb)\n",
    "\n",
    "Research Paper : [No Language Left Behind:Scaling Human-Centered Machine Translation](https://arxiv.org/abs/2207.04672)\n",
    "\n",
    "\n",
    "\n",
    "Create two dictionaries 1. for holding our tokenizers and 2. for holding all the vocabs with assigned numbers for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc56da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1045e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.cli import download\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "_MODEL_DIRECTORY = \"./../models\"\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs(_MODEL_DIRECTORY, exist_ok=True)\n",
    "\n",
    "_SPACY_MODEL_PATH = os.path.join(_MODEL_DIRECTORY, \"en_core_web_sm\")\n",
    "\n",
    "def load_spacy_model():\n",
    "    \"\"\"Load spaCy model from custom directory, download if needed\"\"\"\n",
    "    # Check if config.cfg exists (proper model structure)\n",
    "    if os.path.exists(os.path.join(_SPACY_MODEL_PATH, \"config.cfg\")):\n",
    "        return spacy.load(_SPACY_MODEL_PATH)\n",
    "    \n",
    "    # Download and copy to custom folder\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    download(\"en_core_web_sm\")\n",
    "    \n",
    "    import en_core_web_sm\n",
    "    source_path = en_core_web_sm.__path__[0]\n",
    "    \n",
    "    # Find the actual model directory (contains config.cfg)\n",
    "    # It's usually nested like: en_core_web_sm/en_core_web_sm-3.x.x/\n",
    "    # Config checks added to fix - OSError: [E053] Could not read config file from ../models/en_core_web_sm/config.cfg\n",
    "    config_files = glob.glob(os.path.join(source_path, \"**\", \"config.cfg\"), recursive=True)\n",
    "    if config_files:\n",
    "        actual_model_dir = os.path.dirname(config_files[0])\n",
    "    else:\n",
    "        actual_model_dir = source_path\n",
    "    \n",
    "    # Copy the actual model files\n",
    "    os.makedirs(_MODEL_DIRECTORY, exist_ok=True)\n",
    "    if os.path.exists(_SPACY_MODEL_PATH):\n",
    "        shutil.rmtree(_SPACY_MODEL_PATH)\n",
    "    shutil.copytree(actual_model_dir, _SPACY_MODEL_PATH)\n",
    "    \n",
    "    # Load spaCy models directly (faster than get_tokenizer for batch processing)\n",
    "    return spacy.load(_SPACY_MODEL_PATH, disable=[\"parser\", \"tagger\", \"ner\", \"lemmatizer\"])\n",
    "\n",
    "\n",
    "def load_nllb():\n",
    "    \"\"\"Load NLLB tokenizer from custom directory, download if needed\"\"\"\n",
    "    nllb_path = os.path.join(_MODEL_DIRECTORY, \"nllb-tokenizer\")\n",
    "    if os.path.exists(nllb_path):\n",
    "        return AutoTokenizer.from_pretrained(nllb_path)\n",
    "    \n",
    "    print(\"Downloading NLLB tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "    tokenizer.save_pretrained(nllb_path)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec51eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = load_spacy_model()\n",
    "\n",
    "# Add English tokenizer to token_transform\n",
    "def spacy_tokenize(text):\n",
    "    \"\"\"Tokenize text using spaCy\"\"\"\n",
    "    return [tok.text for tok in spacy_model(text)]\n",
    "\n",
    "token_transform[_EN_LANGUAGE] = spacy_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "321e56c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁नेपाल', '▁सुन्दर', '▁छ']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "nllb = load_nllb()\n",
    "sample_nepali_sentence = \"नेपाल सुन्दर छ\"\n",
    "\n",
    "# Add Nepali tokenizer to token_transform\n",
    "token_transform[_NE_LANGUAGE] = nllb.tokenize\n",
    "\n",
    "print(token_transform[_NE_LANGUAGE](sample_nepali_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce3e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: निम्न वस्तुको म्याद समाप्त हुन्छ:\n",
      "Tokenization:  ['▁निम्न', '▁वस्तु', 'को', '▁म्या', 'द', '▁समाप्त', '▁हुन्छ', ':']\n"
     ]
    }
   ],
   "source": [
    "train_nepali_text = train[100]['translation'][_NE_LANGUAGE]\n",
    "print(\"Sentence:\", train_nepali_text)\n",
    "print(\"Tokenization: \", token_transform[_NE_LANGUAGE](train_nepali_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334ee1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The following item is due:\n",
      "Tokenization:  ['The', 'following', 'item', 'is', 'due', ':']\n"
     ]
    }
   ],
   "source": [
    "#example of tokenization of the english part\n",
    "train_english_text = train[100]['translation'][_EN_LANGUAGE]\n",
    "print(\"Sentence:\", train_english_text)\n",
    "print(\"Tokenization: \", token_transform[_EN_LANGUAGE](train_english_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d0cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SRC_LANGUAGE = _EN_LANGUAGE\n",
    "_TRG_LANGUAGE = _NE_LANGUAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9527850d",
   "metadata": {},
   "source": [
    "Function to token input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b1a7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    for data_sample in data:\n",
    "        yield token_transform[language](data_sample['translation'][language])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121201d0",
   "metadata": {},
   "source": [
    "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence.\n",
    "\n",
    "special symbols `<unk>`, `<pad>`, `<sos>`, `<eos>` with indexes 0, 1, 2, 3 respectively. Where each symbol has meanings as such:\n",
    ">\n",
    ">   `<unk>`: To represent Unknown\n",
    ">\n",
    ">   `<pad>`: Padding, used to ensure all sequences are of same length\n",
    ">\n",
    ">   `<sos>`: Start of sentence\n",
    ">\n",
    ">   `<eos>`: End of sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5cf598",
   "metadata": {},
   "source": [
    "#### Step 4: Numericalization\n",
    "\n",
    "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we build Vocab class as torchtext.vocab is not supported in Python v3.13+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3950602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext.vocab replacement - Vocab class to mimic torchtext API\n",
    "from collections import Counter\n",
    "\n",
    "# Define special symbols and indices\n",
    "_UNK_IDX, _PAD_IDX, _SOS_IDX, _EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "_SPECIAL_SYMBOLS = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"A simple Vocab class to replace torchtext.vocab\"\"\"\n",
    "    def __init__(self, stoi, itos, default_index=0):\n",
    "        self.stoi = stoi  # string to index\n",
    "        self.itos = itos  # index to string (list)\n",
    "        self.default_index = default_index\n",
    "    \n",
    "    def __call__(self, tokens):\n",
    "        \"\"\"Convert list of tokens to list of indices\"\"\"\n",
    "        return [self.stoi.get(token, self.default_index) for token in tokens]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    def __getitem__(self, token):\n",
    "        return self.stoi.get(token, self.default_index)\n",
    "    \n",
    "    def set_default_index(self, index):\n",
    "        self.default_index = index\n",
    "    \n",
    "    def get_itos(self):\n",
    "        return self.itos\n",
    "\n",
    "def build_vocab(token_iterator, min_freq=2, specials=None, special_first=True):\n",
    "    \"\"\"Build vocabulary from token iterator\"\"\"\n",
    "    if specials is None:\n",
    "        specials = []\n",
    "    \n",
    "    # Count token frequencies\n",
    "    counter = Counter()\n",
    "    for tokens in token_iterator:\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    # Build itos (index to string) list\n",
    "    itos = []\n",
    "    if special_first:\n",
    "        itos.extend(specials)\n",
    "    \n",
    "    # Add tokens that meet min_freq threshold\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= min_freq and token not in specials:\n",
    "            itos.append(token)\n",
    "    \n",
    "    if not special_first:\n",
    "        itos.extend(specials)\n",
    "    \n",
    "    # Build stoi (string to index) dict\n",
    "    stoi = {token: idx for idx, token in enumerate(itos)}\n",
    "    \n",
    "    return Vocab(stoi, itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3897997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocab for en (batch mode)...Building vocab for ne...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting EN texts: 100%|██████████| 20000/20000 [00:00<00:00, 182383.25it/s]\n",
      "Tokenizing NE: 100%|██████████| 20000/20000 [00:00<00:00, 30509.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ne done in 0.7s, vocab size: 4785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing EN: 100%|██████████| 20000/20000 [00:12<00:00, 1653.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  en done in 12.2s, vocab size: 6151\n",
      "\n",
      "Total time: 12.2s\n",
      "en vocab size: 6151\n",
      "ne vocab size: 4785\n",
      "NLLB tokenizer warning about max sequence length may be ignored for vocab building. \n",
      "It is only used as a tokenizer here. The 1024 limit applies during model training/inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_vocab_en_fast(data):\n",
    "    \"\"\"Build English vocab using spaCy's fast pipe() method\"\"\"\n",
    "    print(f\"Building vocab for {_EN_LANGUAGE} (batch mode)...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Collect all English texts\n",
    "    texts = [sample['translation'][_EN_LANGUAGE] for sample in tqdm(data, desc=\"Collecting EN texts\")]\n",
    "    \n",
    "    # Batch tokenize with spaCy pipe() - MUCH faster!\n",
    "    counter = Counter()\n",
    "    for doc in tqdm(spacy_model.pipe(texts, batch_size=1000, n_process=1), \n",
    "                    total=len(texts), desc=\"Tokenizing EN\"):\n",
    "        counter.update([tok.text for tok in doc])\n",
    "    \n",
    "    # Build vocab\n",
    "    itos = list(_SPECIAL_SYMBOLS)\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= 2 and token not in _SPECIAL_SYMBOLS:\n",
    "            itos.append(token)\n",
    "    stoi = {token: idx for idx, token in enumerate(itos)}\n",
    "    \n",
    "    vocab = Vocab(stoi, itos)\n",
    "    vocab.set_default_index(_UNK_IDX)\n",
    "    print(f\"  {_EN_LANGUAGE} done in {time.time() - start:.1f}s, vocab size: {len(vocab)}\")\n",
    "    return vocab\n",
    "\n",
    "def build_vocab_ne(data):\n",
    "    \"\"\"Build Nepali vocab (NLLB tokenizer)\"\"\"\n",
    "    print(f\"Building vocab for {_NE_LANGUAGE}...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    counter = Counter()\n",
    "    for sample in tqdm(data, desc=\"Tokenizing NE\"):\n",
    "        tokens = token_transform[_NE_LANGUAGE](sample['translation'][_NE_LANGUAGE])\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    # Build vocab\n",
    "    itos = list(_SPECIAL_SYMBOLS)\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= 2 and token not in _SPECIAL_SYMBOLS:\n",
    "            itos.append(token)\n",
    "    stoi = {token: idx for idx, token in enumerate(itos)}\n",
    "    \n",
    "    vocab = Vocab(stoi, itos)\n",
    "    vocab.set_default_index(_UNK_IDX)\n",
    "    print(f\"  {_NE_LANGUAGE} done in {time.time() - start:.1f}s, vocab size: {len(vocab)}\")\n",
    "    return vocab\n",
    "\n",
    "# Build vocabularies in parallel\n",
    "start_total = time.time()\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    future_en = executor.submit(build_vocab_en_fast, train)\n",
    "    future_ne = executor.submit(build_vocab_ne, train)\n",
    "    \n",
    "    vocab_transform[_EN_LANGUAGE] = future_en.result()\n",
    "    vocab_transform[_NE_LANGUAGE] = future_ne.result()\n",
    "\n",
    "print(f\"\\nTotal time: {time.time() - start_total:.1f}s\")\n",
    "print(f\"{_SRC_LANGUAGE} vocab size: {len(vocab_transform[_SRC_LANGUAGE])}\")\n",
    "print(f\"{_TRG_LANGUAGE} vocab size: {len(vocab_transform[_TRG_LANGUAGE])}\")\n",
    "\n",
    "# Warning : Token indices sequence length is longer than the specified maximum sequence length for this model (3645 > 1024). Running this sequence through the model will result in indexing errors\n",
    "print(\"\"\"NLLB tokenizer warning about max sequence length may be ignored for vocab building. \n",
    "It is only used as a tokenizer here. The 1024 limit applies during model training/inference.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3b18a",
   "metadata": {},
   "source": [
    "The parallalization addition didn't benefit much as the volume of Nepali dataset was not huge and NLLB is fast since it's implemented in Rust and it only took few seconds to get competed. \n",
    "\n",
    "The main time consuming tokenization was for EN language. After using `pipe()` for batch processing , the number reduced by more than 50%. It takes little more than 1 minute compared to ~3 minutes without batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fece20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2412, 271, 201, 0, 201]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transform[_SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4072856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lower'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can reverse it....\n",
    "mapping = vocab_transform[_SRC_LANGUAGE].get_itos()\n",
    "\n",
    "#print 2822, for example\n",
    "mapping[2822]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "311e3a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4694794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1554346b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6151"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82847c1a",
   "metadata": {},
   "source": [
    "#### Step 5: Prepare data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ccb17",
   "metadata": {},
   "source": [
    "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "265d2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([_SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([_EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [_SRC_LANGUAGE, _TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for sample in batch:\n",
    "        # OPUS-100 format: {'translation': {'en': '...', 'ne': '...'}}\n",
    "        src_sample = sample['translation'][_SRC_LANGUAGE]\n",
    "        trg_sample = sample['translation'][_TRG_LANGUAGE]\n",
    "        \n",
    "        processed_text = text_transform[_SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[_TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=_PAD_IDX)\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=_PAD_IDX)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088c811",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4095d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce batch size for MPS memory constraints (64 -> 32)\n",
    "_BATCH_SIZE = 16 #32\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=_BATCH_SIZE, shuffle=True,  collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val,   batch_size=_BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test,  batch_size=_BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a99656",
   "metadata": {},
   "source": [
    "Let's test the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ec564dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, ne in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba6f7d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English shape:  torch.Size([11, 16])\n",
      "Nepali shape:  torch.Size([39, 16])\n"
     ]
    }
   ],
   "source": [
    "print(\"English shape: \", en.shape)  # (seq len, batch_size)\n",
    "print(\"Nepali shape: \", ne.shape)   # (seq len, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10392f3a",
   "metadata": {},
   "source": [
    "## Task 2. Experiment with Attention Mechanisms - Implement a sequence-to-sequence neural network for the translation task. Your implementation should include the following attention mechanisms, with their respective equations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991eb68f",
   "metadata": {},
   "source": [
    "\n",
    "Note: For an in-depth exploration of attention mechanisms, you can refer to this $paper^1$.\n",
    "\n",
    "$^1$ An Attentive Survey of Attention Models https://arxiv.org/pdf/1904.02874.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c3c919",
   "metadata": {},
   "source": [
    "##### Step 6: Design Model :: Seq-to-Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "958c82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqPackedAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device  = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        #src: [src len, batch_size]\n",
    "        mask = (src == self.src_pad_idx).permute(1, 0)  #permute so that it's the same shape as attention\n",
    "        #mask: [batch_size, src len] #(0, 0, 0, 0, 0, 1, 1)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        #src: [src len, batch_size]\n",
    "        #trg: [trg len, batch_size]\n",
    "        \n",
    "        #initialize something\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len    = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs    = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        attentions = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n",
    "        \n",
    "        #send our src text into encoder\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "        #encoder_outputs refer to all hidden states (last layer)\n",
    "        #hidden refer to the last hidden state (of each layer, of each direction)\n",
    "        \n",
    "        input_ = trg[0, :]\n",
    "        \n",
    "        mask   = self.create_mask(src) #(0, 0, 0, 0, 0, 1, 1)\n",
    "        \n",
    "        #for each of the input of the trg text\n",
    "        for t in range(1, trg_len):\n",
    "            #send them to the decoder\n",
    "            output, hidden, attention = self.decoder(input_, hidden, encoder_outputs, mask)\n",
    "            #output: [batch_size, output_dim] ==> predictions\n",
    "            #hidden: [batch_size, hid_dim]\n",
    "            #attention: [batch_size, src len]\n",
    "            \n",
    "            #append the output to a list\n",
    "            outputs[t] = output\n",
    "            attentions[t] = attention\n",
    "            \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1          = output.argmax(1)  #autoregressive\n",
    "            \n",
    "            input_ = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1870050",
   "metadata": {},
   "source": [
    "#### Step 7: Design Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bdf5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn       = nn.GRU(emb_dim, hid_dim, bidirectional=True)\n",
    "        self.fc        = nn.Linear(hid_dim * 2, hid_dim)\n",
    "        self.dropout   = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        #embedding\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #packed\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'), enforce_sorted=False)\n",
    "        #rnn\n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "        #unpacked\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        #-1, -2 hidden state\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim = 1)))\n",
    "        \n",
    "        #outputs: [src len, batch_size, hid dim * 2]\n",
    "        #hidden:  [batch_size, hid_dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed28218",
   "metadata": {},
   "source": [
    "### 2.1) General Attention: (0.5 points)\n",
    "\n",
    "$$e_i = s^T h_i \\in \\mathbb{R} \\quad \\text{where} \\quad d_1 = d_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea30eb",
   "metadata": {},
   "source": [
    "#### Step 8: Design Attention Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f68a96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    General (Dot-Product) Attention: e_i = s^T h_i\n",
    "    Requires projection to match dimensions\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # Project encoder outputs to match decoder hidden dim\n",
    "        # enc_hid_dim is already the full encoder output dim (hid_dim * 2 for bidirectional)\n",
    "        self.proj = nn.Linear(enc_hid_dim, dec_hid_dim)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: [batch_size, dec_hid_dim]\n",
    "        # encoder_outputs: [src_len, batch_size, enc_hid_dim]\n",
    "        \n",
    "        # Project encoder outputs to decoder dimension\n",
    "        encoder_projected = self.proj(encoder_outputs)  # [src_len, batch_size, dec_hid_dim]\n",
    "        encoder_projected = encoder_projected.permute(1, 0, 2)  # [batch_size, src_len, dec_hid_dim]\n",
    "        \n",
    "        hidden = hidden.unsqueeze(2)  # [batch_size, dec_hid_dim, 1]\n",
    "        \n",
    "        # Dot product attention: s^T h\n",
    "        attention = torch.bmm(encoder_projected, hidden).squeeze(2)  # [batch_size, src_len]\n",
    "        \n",
    "        # Mask padding tokens\n",
    "        attention = attention.masked_fill(mask, -1e10)\n",
    "        \n",
    "        return torch.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112803a",
   "metadata": {},
   "source": [
    "### Extra for learning - Multiplicative Attention: \n",
    "\n",
    "$$e_i = s^T W h_i \\in \\mathbb{R} \\quad \\text{where} \\quad W \\in \\mathbb{R}^{d_2 \\times d_1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13dd2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplicativeAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multiplicative Attention: e_i = s^T W h_i\n",
    "    W is a learnable weight matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # W matrix: maps encoder hidden to decoder hidden space\n",
    "        # enc_hid_dim is already the full encoder output dim (hid_dim * 2 for bidirectional)\n",
    "        self.W = nn.Linear(enc_hid_dim, dec_hid_dim, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: [batch_size, dec_hid_dim]\n",
    "        # encoder_outputs: [src_len, batch_size, enc_hid_dim]\n",
    "        \n",
    "        # Apply W to encoder outputs\n",
    "        encoder_transformed = self.W(encoder_outputs)  # [src_len, batch_size, dec_hid_dim]\n",
    "        encoder_transformed = encoder_transformed.permute(1, 0, 2)  # [batch_size, src_len, dec_hid_dim]\n",
    "        \n",
    "        hidden = hidden.unsqueeze(2)  # [batch_size, dec_hid_dim, 1]\n",
    "        \n",
    "        # s^T W h\n",
    "        attention = torch.bmm(encoder_transformed, hidden).squeeze(2)  # [batch_size, src_len]\n",
    "        \n",
    "        # Mask padding tokens\n",
    "        attention = attention.masked_fill(mask, -1e10)\n",
    "        \n",
    "        return torch.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1f150",
   "metadata": {},
   "source": [
    "### 2.2) Additive Attention: (0.5 points)\n",
    "\n",
    "$$e_i = v^t \\tanh(W_1 h_i + W_2 s) \\in \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1c78c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Additive (Bahdanau) Attention: e_i = v^T tanh(W1 h_i + W2 s)\n",
    "    Most flexible - different dimensions allowed\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # enc_hid_dim is already the full encoder output dim (hid_dim * 2 for bidirectional)\n",
    "        self.W1 = nn.Linear(enc_hid_dim, dec_hid_dim)  # for encoder hidden\n",
    "        self.W2 = nn.Linear(dec_hid_dim, dec_hid_dim)  # for decoder hidden\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False) # to get scalar score\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: [batch_size, dec_hid_dim]\n",
    "        # encoder_outputs: [src_len, batch_size, enc_hid_dim]\n",
    "        \n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        # Repeat hidden for each source position\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # [batch_size, src_len, dec_hid_dim]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # [batch_size, src_len, enc_hid_dim]\n",
    "        \n",
    "        # v^T tanh(W1 h + W2 s)\n",
    "        energy = torch.tanh(self.W1(encoder_outputs) + self.W2(hidden))  # [batch_size, src_len, dec_hid_dim]\n",
    "        attention = self.v(energy).squeeze(2)  # [batch_size, src_len]\n",
    "        \n",
    "        # Mask padding tokens\n",
    "        attention = attention.masked_fill(mask, -1e10)\n",
    "        \n",
    "        return torch.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5f42c",
   "metadata": {},
   "source": [
    "### Design Decoder with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a0c5b",
   "metadata": {},
   "source": [
    "#### Step 9: Design decoder to pass attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5db091f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention  = attention\n",
    "        self.embedding  = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn        = nn.GRU((hid_dim * 2) + emb_dim, hid_dim)\n",
    "        self.fc         = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
    "        self.dropout    = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "        #input: [batch_size]\n",
    "        #hidden: [batch_size, hid_dim]\n",
    "        #encoder_ouputs: [src len, batch_size, hid_dim * 2]\n",
    "        #mask: [batch_size, src len]\n",
    "                \n",
    "        #embed our input\n",
    "        input    = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #embedded = [1, batch_size, emb_dim]\n",
    "        \n",
    "        #calculate the attention\n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "        #a = [batch_size, src len]\n",
    "        a = a.unsqueeze(1)\n",
    "        #a = [batch_size, 1, src len]\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #encoder_ouputs: [batch_size, src len, hid_dim * 2]\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        #weighted: [batch_size, 1, hid_dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        #weighted: [1, batch_size, hid_dim * 2]\n",
    "        \n",
    "        #send the input to decoder rnn\n",
    "            #concatenate (embed, weighted encoder_outputs)\n",
    "            #[1, batch_size, emb_dim]; [1, batch_size, hid_dim * 2]\n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        #rnn_input: [1, batch_size, emb_dim + hid_dim * 2]\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "            \n",
    "        #send the output of the decoder rnn to fc layer to predict the word\n",
    "            #prediction = fc(concatenate (output, weighted, embed))\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output   = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc(torch.cat((embedded, output, weighted), dim = 1))\n",
    "        #prediction: [batch_size, output_dim]\n",
    "            \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd53ac",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a83ba0",
   "metadata": {},
   "source": [
    "#### Step 10: Model Training\n",
    "\n",
    "We use a simplified version of the weight initialization scheme used in the paper. Here, we will initialize all biases to zero and all weights from $\\mathcal{N}(0, 0.01)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f8f0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0513261",
   "metadata": {},
   "source": [
    "Desgin mode to accept custom attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90a6e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with general attention...\n",
      "Seq2SeqPackedAttention(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(6151, 64)\n",
      "    (rnn): GRU(64, 256, bidirectional=True)\n",
      "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): GeneralAttention(\n",
      "      (proj): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (embedding): Embedding(4785, 64)\n",
      "    (rnn): GRU(576, 256)\n",
      "    (fc): Linear(in_features=832, out_features=4785, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Creating model with multiplicative attention...\n",
      "Seq2SeqPackedAttention(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(6151, 64)\n",
      "    (rnn): GRU(64, 256, bidirectional=True)\n",
      "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): MultiplicativeAttention(\n",
      "      (W): Linear(in_features=512, out_features=256, bias=False)\n",
      "    )\n",
      "    (embedding): Embedding(4785, 64)\n",
      "    (rnn): GRU(576, 256)\n",
      "    (fc): Linear(in_features=832, out_features=4785, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Creating model with additive attention...\n",
      "Seq2SeqPackedAttention(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(6151, 64)\n",
      "    (rnn): GRU(64, 256, bidirectional=True)\n",
      "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): AdditiveAttention(\n",
      "      (W1): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (W2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
      "    )\n",
      "    (embedding): Embedding(4785, 64)\n",
      "    (rnn): GRU(576, 256)\n",
      "    (fc): Linear(in_features=832, out_features=4785, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_INPUT_DIM   = len(vocab_transform[_SRC_LANGUAGE])\n",
    "_OUTPUT_DIM  = len(vocab_transform[_TRG_LANGUAGE])\n",
    "\n",
    "_EMB_DIM     = 64 #256  \n",
    "_HID_DIM     = 256 #512  \n",
    "_DROPOUT     = 0.5\n",
    "_SRC_PAD_IDX = _PAD_IDX\n",
    "\n",
    "attention_models = {}\n",
    "\n",
    "attention_models['general']        = GeneralAttention(_HID_DIM * 2, _HID_DIM)\n",
    "attention_models['multiplicative'] = MultiplicativeAttention(_HID_DIM * 2, _HID_DIM)\n",
    "attention_models['additive']       = AdditiveAttention(_HID_DIM * 2, _HID_DIM)\n",
    "\n",
    "\n",
    "def get_model_with_attention(attention_type='general'):\n",
    "    attn = attention_models.get(attention_type)\n",
    "    \n",
    "    if attn is None:\n",
    "        raise ValueError(f\"Unknown attention type: {attention_type}\")\n",
    "    \n",
    "    enc  = Encoder(_INPUT_DIM,  _EMB_DIM,  _HID_DIM, _DROPOUT)\n",
    "    dec  = Decoder(_OUTPUT_DIM, _EMB_DIM,  _HID_DIM, _DROPOUT, attn)\n",
    "\n",
    "    model = Seq2SeqPackedAttention(enc, dec, _SRC_PAD_IDX, device).to(device)\n",
    "    model.apply(initialize_weights)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "seq2seq_models = {}\n",
    "\n",
    "\n",
    "# Create models with different attention mechanisms\n",
    "for attention_type in attention_models.keys():\n",
    "    print(f\"Creating model with {attention_type} attention...\")\n",
    "    seq2seq_models[attention_type] = get_model_with_attention(attention_type)\n",
    "    print(seq2seq_models[attention_type])\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0869af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters for general attention:\n",
      "393664\n",
      " 49152\n",
      "196608\n",
      "   768\n",
      "   768\n",
      " 49152\n",
      "196608\n",
      "   768\n",
      "   768\n",
      "131072\n",
      "   256\n",
      "131072\n",
      "   256\n",
      "306240\n",
      "442368\n",
      "196608\n",
      "   768\n",
      "   768\n",
      "3981120\n",
      "  4785\n",
      "______\n",
      "6083569\n",
      "Model parameters for multiplicative attention:\n",
      "393664\n",
      " 49152\n",
      "196608\n",
      "   768\n",
      "   768\n",
      " 49152\n",
      "196608\n",
      "   768\n",
      "   768\n",
      "131072\n",
      "   256\n",
      "131072\n",
      "306240\n",
      "442368\n",
      "196608\n",
      "   768\n",
      "   768\n",
      "3981120\n",
      "  4785\n",
      "______\n",
      "6083313\n",
      "Model parameters for additive attention:\n",
      "393664\n",
      " 49152\n",
      "196608\n",
      "   768\n",
      "   768\n",
      " 49152\n",
      "196608\n",
      "   768\n",
      "   768\n",
      "131072\n",
      "   256\n",
      "131072\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "   256\n",
      "306240\n",
      "442368\n",
      "196608\n",
      "   768\n",
      "   768\n",
      "3981120\n",
      "  4785\n",
      "______\n",
      "6149617\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "\n",
    "for attention_type, local_model in seq2seq_models.items():\n",
    "    print(f\"Model parameters for {attention_type} attention:\")\n",
    "    count_parameters(local_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb15718",
   "metadata": {},
   "source": [
    "Our loss function calculates the average loss per token, however by passing the index of the `<pad>` token as the `ignore_index` argument we ignore the loss whenever the target token is a padding token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb9e8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_length, trg in loader:\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, attentions = model(src, src_length, trg)\n",
    "        \n",
    "        #trg    = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        #the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg    = trg[1:].view(-1)\n",
    "        #trg    = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #clip the gradients to prevent them from exploding (a common issue in RNNs)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Clear MPS cache periodically to prevent memory buildup\n",
    "        if device.type == 'mps':\n",
    "            torch.mps.empty_cache()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b5e40",
   "metadata": {},
   "source": [
    "## Task 3. Evaluation and Verification - For the final evaluation and verification, perform the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7086504",
   "metadata": {},
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2bda5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "        \n",
    "    #turn off dropout (and batch norm if used)\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for src, src_length, trg in loader:\n",
    "        \n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg    = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg    = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb46a1",
   "metadata": {},
   "source": [
    "Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccd123c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 125, 125)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_length = len(train_loader)\n",
    "val_loader_length   = len(valid_loader)\n",
    "test_loader_length  = len(test_loader)\n",
    "\n",
    "train_loader_length, val_loader_length, test_loader_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "597b3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84a481",
   "metadata": {},
   "source": [
    "#### Step 11. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e80bf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 19s\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.244\n",
      "\t Val. Loss: 5.687 |  Val. PPL: 294.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 19s\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.244\n",
      "\t Val. Loss: 5.687 |  Val. PPL: 294.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:54<04:35, 137.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 19s\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.244\n",
      "\t Val. Loss: 5.687 |  Val. PPL: 294.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:54<04:35, 137.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 16s\n",
      "\tTrain Loss: 4.717 | Train PPL: 111.793\n",
      "\t Val. Loss: 5.586 |  Val. PPL: 266.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 19s\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.244\n",
      "\t Val. Loss: 5.687 |  Val. PPL: 294.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:54<04:35, 137.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 16s\n",
      "\tTrain Loss: 4.717 | Train PPL: 111.793\n",
      "\t Val. Loss: 5.586 |  Val. PPL: 266.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [09:11<02:17, 137.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 19s\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.244\n",
      "\t Val. Loss: 5.687 |  Val. PPL: 294.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:54<04:35, 137.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 16s\n",
      "\tTrain Loss: 4.717 | Train PPL: 111.793\n",
      "\t Val. Loss: 5.586 |  Val. PPL: 266.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [09:11<02:17, 137.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 16s\n",
      "\tTrain Loss: 4.258 | Train PPL:  70.635\n",
      "\t Val. Loss: 5.569 |  Val. PPL: 262.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 19s\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.244\n",
      "\t Val. Loss: 5.687 |  Val. PPL: 294.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:54<04:35, 137.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 16s\n",
      "\tTrain Loss: 4.717 | Train PPL: 111.793\n",
      "\t Val. Loss: 5.586 |  Val. PPL: 266.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [09:11<02:17, 137.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 16s\n",
      "\tTrain Loss: 4.258 | Train PPL:  70.635\n",
      "\t Val. Loss: 5.569 |  Val. PPL: 262.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [11:29<00:00, 137.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Model with general attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:04<08:18, 124.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 5.443 | Train PPL: 231.246\n",
      "\t Val. Loss: 5.863 |  Val. PPL: 351.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:09<06:14, 124.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 5s\n",
      "\tTrain Loss: 4.925 | Train PPL: 137.727\n",
      "\t Val. Loss: 5.754 |  Val. PPL: 315.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:14<04:09, 124.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 4s\n",
      "\tTrain Loss: 4.541 | Train PPL:  93.794\n",
      "\t Val. Loss: 5.696 |  Val. PPL: 297.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:20<02:05, 125.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
      "\t Val. Loss: 5.630 |  Val. PPL: 278.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:28<00:00, 125.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 7s\n",
      "\tTrain Loss: 3.936 | Train PPL:  51.193\n",
      "\t Val. Loss: 5.658 |  Val. PPL: 286.454\n",
      "\n",
      "========= Model with multiplicative attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:07<08:30, 127.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 7s\n",
      "\tTrain Loss: 6.195 | Train PPL: 490.048\n",
      "\t Val. Loss: 5.947 |  Val. PPL: 382.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:13<06:20, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 6s\n",
      "\tTrain Loss: 5.309 | Train PPL: 202.189\n",
      "\t Val. Loss: 5.789 |  Val. PPL: 326.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:21<04:14, 127.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 7s\n",
      "\tTrain Loss: 4.811 | Train PPL: 122.834\n",
      "\t Val. Loss: 5.666 |  Val. PPL: 288.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [08:27<02:06, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 6s\n",
      "\tTrain Loss: 4.432 | Train PPL:  84.059\n",
      "\t Val. Loss: 5.624 |  Val. PPL: 277.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [10:34<00:00, 126.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 6s\n",
      "\tTrain Loss: 4.139 | Train PPL:  62.741\n",
      "\t Val. Loss: 5.610 |  Val. PPL: 273.135\n",
      "\n",
      "========= Model with additive attention =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [02:18<09:14, 138.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 18s\n",
      "\tTrain Loss: 6.179 | Train PPL: 482.609\n",
      "\t Val. Loss: 5.919 |  Val. PPL: 371.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [04:37<06:56, 138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 19s\n",
      "\tTrain Loss: 5.264 | Train PPL: 193.244\n",
      "\t Val. Loss: 5.687 |  Val. PPL: 294.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [06:54<04:35, 137.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 16s\n",
      "\tTrain Loss: 4.717 | Train PPL: 111.793\n",
      "\t Val. Loss: 5.586 |  Val. PPL: 266.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [09:11<02:17, 137.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 16s\n",
      "\tTrain Loss: 4.258 | Train PPL:  70.635\n",
      "\t Val. Loss: 5.569 |  Val. PPL: 262.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [11:29<00:00, 137.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 18s\n",
      "\tTrain Loss: 3.891 | Train PPL:  48.957\n",
      "\t Val. Loss: 5.507 |  Val. PPL: 246.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "_LEARNING_RATE = 0.001\n",
    "_NUM_EPOCHS = 5\n",
    "_CLIP       = 1\n",
    "\n",
    "train_losses = {}\n",
    "valid_losses = {}\n",
    "\n",
    "for attention_type, model in seq2seq_models.items():\n",
    "    best_valid_loss = float('inf')\n",
    "    #training hyperparameters\n",
    "    optimizer = optim.Adam(model.parameters(), lr=_LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = _PAD_IDX) #combine softmax with cross entropy\n",
    "\n",
    "    # Clear MPS cache before training\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "    save_path = f'{_MODEL_DIRECTORY}/{model.__class__.__name__}_{attention_type}.pt'\n",
    "\n",
    "    print(f'\\n========= Model with {attention_type} attention =========')\n",
    "\n",
    "    # for epoch in range(_NUM_EPOCHS):\n",
    "    for epoch in tqdm(range(_NUM_EPOCHS), desc=\"Epochs\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, _CLIP, train_loader_length)\n",
    "        valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
    "        \n",
    "        #for plotting\n",
    "        train_losses.setdefault(attention_type, []).append(train_loss)\n",
    "        valid_losses.setdefault(attention_type, []).append(valid_loss)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        # Save the model if validation loss decreases\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "        tqdm.write(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        tqdm.write(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        tqdm.write(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "        # print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        # print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "        \n",
    "        # Clear cache after each epoch\n",
    "        if device.type == 'mps':\n",
    "            torch.mps.empty_cache()\n",
    "        \n",
    "        #lower perplexity is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa3265",
   "metadata": {},
   "source": [
    "### 3.1) Compare the performance of these attention mechanisms in terms of translation accuracy, computational efficiency, and other relevant metrics. (1 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12a231",
   "metadata": {},
   "source": [
    "#### Step 12. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47f9512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (general): 23.21 MB\n",
      "Loaded model: general\n",
      "Model size (multiplicative): 23.21 MB\n",
      "Loaded model: multiplicative\n",
      "Model size (additive): 23.47 MB\n",
      "Loaded model: additive\n"
     ]
    }
   ],
   "source": [
    "final_models = {}\n",
    "\n",
    "for attention_type in attention_models.keys():\n",
    "    model_file_name = f'Seq2SeqPackedAttention_{attention_type}.pt'\n",
    "    load_path = f'{_MODEL_DIRECTORY}/{model_file_name}'\n",
    "\n",
    "    model_size = os.path.getsize(load_path) / (1024 * 1024)  # Size (MB)\n",
    "    print(f\"Model size ({attention_type}): {model_size:.2f} MB\")\n",
    "\n",
    "    # Load model state dict (not params tuple)\n",
    "    final_models[attention_type] = seq2seq_models[attention_type]\n",
    "    final_models[attention_type].load_state_dict(torch.load(load_path, map_location=device))\n",
    "    final_models[attention_type].eval()\n",
    "    print(f\"Loaded model: {attention_type}\")\n",
    "\n",
    "\n",
    "def translate(src_text, attention_type='additive', max_len=15):\n",
    "    start_time = time.time()\n",
    "    \"\"\"Translate source text without needing target text (autoregressive inference)\"\"\"\n",
    "    model = final_models[attention_type]\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and numericalize source text\n",
    "    src_tokens = text_transform[_SRC_LANGUAGE](src_text)\n",
    "    src_tensor = src_tokens.unsqueeze(1).to(device)  # [src_len, 1]\n",
    "    src_len = torch.tensor([src_tokens.size(0)], dtype=torch.int64)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode source\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
    "        mask = model.create_mask(src_tensor)\n",
    "        \n",
    "        # Start with <sos> token\n",
    "        input_token = torch.tensor([_SOS_IDX], device=device)\n",
    "        \n",
    "        output_tokens = []\n",
    "        attentions = []\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            # Decode one step\n",
    "            output, hidden, attention = model.decoder(input_token, hidden, encoder_outputs, mask)\n",
    "            attentions.append(attention)\n",
    "            \n",
    "            # Get predicted token\n",
    "            pred_token = output.argmax(1).item()\n",
    "            output_tokens.append(pred_token)\n",
    "            \n",
    "            # Stop if <eos>\n",
    "            if pred_token == _EOS_IDX:\n",
    "                break\n",
    "            \n",
    "            # Use prediction as next input\n",
    "            input_token = torch.tensor([pred_token], device=device)\n",
    "    \n",
    "    # Convert tokens to words\n",
    "    mapping = vocab_transform[_TRG_LANGUAGE].get_itos()\n",
    "    translation = [mapping[idx] for idx in output_tokens if idx not in [_SOS_IDX, _EOS_IDX, _PAD_IDX]]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Translation time ({attention_type}): {end_time - start_time:.2f}s\")\n",
    "    \n",
    "    return ' '.join(translation), torch.stack(attentions).squeeze(1)\n",
    "\n",
    "\n",
    "def translate_all_models(src_text):\n",
    "    \"\"\"Translate using all attention models\"\"\"\n",
    "    results = {}\n",
    "    for attention_type in attention_models.keys():\n",
    "        translation, _ = translate(src_text, attention_type)\n",
    "        results[attention_type] = translation\n",
    "        print(f\"{attention_type}: {translation}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "620a2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time (additive): 0.02s\n",
      "Additive translation: <unk> <unk> <unk>\n",
      "torch.Size([4, 4])\n",
      "tensor([[0.0224, 0.8267, 0.1403, 0.0106],\n",
      "        [0.0494, 0.3899, 0.4869, 0.0737],\n",
      "        [0.0191, 0.3938, 0.5570, 0.0300],\n",
      "        [0.0204, 0.1564, 0.7721, 0.0511]], device='mps:0')\n",
      "Translation time (general): 0.01s\n",
      "General translation: <unk> <unk> <unk> <unk>\n",
      "torch.Size([5, 4])\n",
      "tensor([[3.8954e-12, 1.6417e-06, 9.9985e-01, 1.4648e-04],\n",
      "        [9.2088e-15, 2.9811e-08, 9.9947e-01, 5.2982e-04],\n",
      "        [5.5500e-11, 3.0639e-06, 9.0615e-01, 9.3843e-02],\n",
      "        [2.3913e-12, 4.2644e-07, 7.9283e-01, 2.0717e-01],\n",
      "        [4.8214e-13, 2.4080e-08, 3.5624e-02, 9.6438e-01]], device='mps:0')\n",
      "Translation time (multiplicative): 0.01s\n",
      "Multiplicative translation: <unk> वटी\n",
      "torch.Size([3, 4])\n",
      "tensor([[9.6990e-06, 2.2830e-04, 3.3745e-01, 6.6231e-01],\n",
      "        [6.8911e-09, 1.9730e-03, 9.9801e-01, 1.8697e-05],\n",
      "        [3.5636e-07, 2.6437e-04, 9.9967e-01, 6.3441e-05]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello world\"\n",
    "translation, attentions = translate(text, attention_type='additive')\n",
    "print(\"Additive translation:\", translation)\n",
    "\n",
    "# attentions shape: [num_target_tokens, num_source_tokens]\n",
    "print(attentions.shape)\n",
    "print(attentions)  # Each row sums to 1.0\n",
    "\n",
    "translation, attentions = translate(text, attention_type='general')\n",
    "print(\"General translation:\", translation)\n",
    "\n",
    "# attentions shape: [num_target_tokens, num_source_tokens]\n",
    "print(attentions.shape)\n",
    "print(attentions)  # Each row sums to 1.0\n",
    "\n",
    "\n",
    "translation, attentions = translate(text, attention_type='multiplicative')\n",
    "print(\"Multiplicative translation:\", translation)\n",
    "\n",
    "# attentions shape: [num_target_tokens, num_source_tokens]\n",
    "print(attentions.shape)\n",
    "print(attentions)  # Each row sums to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7ec1f",
   "metadata": {},
   "source": [
    "Translate sentence: This is a sample sentence for translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b482a426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time (general): 0.03s\n",
      "Translation with general attention: ▁यो <unk> का ▁लागि का ▁लागि का ▁लागि\n",
      "Translation time (additive): 0.03s\n",
      "Translation with additive attention: ▁यो को का ▁लागि का ▁लागि ▁प्रयोग का उँछ ▁।\n",
      "Translation time (multiplicative): 0.02s\n",
      "Translation with multiplicative attention: ▁यो ले का ▁लागि ▁पास वर्ड हरू ▁।\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sample sentence for translation.\"\n",
    "\n",
    "print(\"Translation with general attention:\", translate(text, attention_type='general')[0])\n",
    "print(\"Translation with additive attention:\", translate(text, attention_type='additive')[0])\n",
    "\n",
    "print(\"Translation with multiplicative attention:\", translate(text, attention_type='multiplicative')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c8cf8b",
   "metadata": {},
   "source": [
    "Translate sentence: Thailand is a beautiful country with rich culture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f9dbc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time (general): 0.03s\n",
      "general: ▁यो <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁।\n",
      "Translation time (multiplicative): 0.03s\n",
      "multiplicative: ▁टो टे म ले ▁एउटा <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "Translation time (additive): 0.02s\n",
      "additive: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁।\n"
     ]
    }
   ],
   "source": [
    "text = \"Thailand is a beautiful country with rich culture.\"\n",
    "\n",
    "translations = translate_all_models(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b16d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time (general): 0.02s\n",
      "general: ▁यो ▁यो ▁मालिक ▁गर्नुहुन्छ ▁?\n",
      "Translation time (multiplicative): 0.02s\n",
      "multiplicative: ▁तपाईँ ले ▁छ\n",
      "Translation time (additive): 0.01s\n",
      "additive: ▁मालिक ▁परिवर्तन ▁गर्नुहुन्छ ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'general': '▁यो ▁यो ▁मालिक ▁गर्नुहुन्छ ▁?',\n",
       " 'multiplicative': '▁तपाईँ ले ▁छ',\n",
       " 'additive': '▁मालिक ▁परिवर्तन ▁गर्नुहुन्छ ?'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"what is this?\"\n",
    "\n",
    "translate_all_models(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b92c6828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general: ▁बधा इ , ,\n",
      "multiplicative: ▁तपाईँ को ▁समाप्त ▁भएको ▁छ ▁।\n",
      "additive: ▁तपाईँ ले ▁चाल लाई ▁नि स्क ▁।\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'general': '▁बधा इ , ,',\n",
       " 'multiplicative': '▁तपाईँ को ▁समाप्त ▁भएको ▁छ ▁।',\n",
       " 'additive': '▁तपाईँ ले ▁चाल लाई ▁नि स्क ▁।'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I will continue later.\"\n",
    "\n",
    "translate_all_models(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b9cfc",
   "metadata": {},
   "source": [
    "Inference on above setences show that all model is highly confused. Multiplicative attention seems to grab some context. Other are basically literal translation of couple of words or partial words from sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7926cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time (general): 0.13s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.02s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "Translation time (general): 0.01s\n",
      "\n",
      "=== GENERAL ===\n",
      "  Parameters: 6,083,569\n",
      "  Model Size: 23.21 MB\n",
      "  Avg Inference: 15.77 ms\n",
      "  Throughput: 63.4 sentences/sec\n",
      "Translation time (multiplicative): 0.08s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "Translation time (multiplicative): 0.01s\n",
      "\n",
      "=== MULTIPLICATIVE ===\n",
      "  Parameters: 6,083,313\n",
      "  Model Size: 23.21 MB\n",
      "  Avg Inference: 14.15 ms\n",
      "  Throughput: 70.7 sentences/sec\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.01s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "Translation time (additive): 0.02s\n",
      "\n",
      "=== ADDITIVE ===\n",
      "  Parameters: 6,149,617\n",
      "  Model Size: 23.46 MB\n",
      "  Avg Inference: 13.12 ms\n",
      "  Throughput: 76.2 sentences/sec\n",
      "\n",
      "============================================================\n",
      "attention_type  total_params  model_size_mb  avg_inference_ms  throughput_sent_per_sec\n",
      "       general       6083569      23.206974         15.771540                63.405348\n",
      "multiplicative       6083313      23.205997         14.147114                70.685795\n",
      "      additive       6149617      23.458927         13.119346                76.223313\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def compute_metrics(model, test_sentences, attention_type, num_runs=10):\n",
    "    \"\"\"Calculate computational efficiency metrics\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Model Parameters (already have)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    # 2. Model Size (MB)\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    model_size_mb = (param_size + buffer_size) / (1024 * 1024)\n",
    "    \n",
    "    # 3. Inference Time (average over multiple runs)\n",
    "    times = []\n",
    "    for sentence in test_sentences:\n",
    "        for _ in range(num_runs):\n",
    "            start = time.perf_counter()\n",
    "            with torch.no_grad():\n",
    "                _, _ = translate(sentence, attention_type)\n",
    "            times.append(time.perf_counter() - start)\n",
    "    \n",
    "    avg_time = sum(times) / len(times)\n",
    "    \n",
    "    # 4. Throughput (sentences per second)\n",
    "    throughput = 1.0 / avg_time\n",
    "    \n",
    "    # 5. Memory Usage (for MPS/CUDA)\n",
    "    if device.type == 'mps':\n",
    "        # MPS doesn't have direct memory query, estimate from model size\n",
    "        memory_mb = model_size_mb * 1.5  # ~1.5x for activations\n",
    "    elif device.type == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        with torch.no_grad():\n",
    "            _, _ = translate(test_sentences[0], attention_type)\n",
    "        memory_mb = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "    else:\n",
    "        memory_mb = model_size_mb\n",
    "    \n",
    "    return {\n",
    "        'attention_type': attention_type,\n",
    "        'total_params': total_params,\n",
    "        'trainable_params': trainable_params,\n",
    "        'model_size_mb': model_size_mb,\n",
    "        'avg_inference_time_s': avg_time,\n",
    "        'throughput_sent_per_sec': throughput,\n",
    "        'memory_mb': memory_mb\n",
    "    }\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"This is a test sentence.\",\n",
    "    \"Nepal is a beautiful country.\"\n",
    "]\n",
    "\n",
    "# Calculate metrics for all models\n",
    "metrics_results = []\n",
    "for attention_type in attention_models.keys():\n",
    "    metrics = compute_metrics(final_models[attention_type], test_sentences, attention_type)\n",
    "    metrics_results.append(metrics)\n",
    "    print(f\"\\n=== {attention_type.upper()} ===\")\n",
    "    print(f\"  Parameters: {metrics['total_params']:,}\")\n",
    "    print(f\"  Model Size: {metrics['model_size_mb']:.2f} MB\")\n",
    "    print(f\"  Avg Inference: {metrics['avg_inference_time_s']*1000:.2f} ms\")\n",
    "    print(f\"  Throughput: {metrics['throughput_sent_per_sec']:.1f} sentences/sec\")\n",
    "\n",
    "# Create comparison table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(metrics_results)\n",
    "df['avg_inference_ms'] = df['avg_inference_time_s'] * 1000\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(df[['attention_type', 'total_params', 'model_size_mb', 'avg_inference_ms', 'throughput_sent_per_sec']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa8946",
   "metadata": {},
   "source": [
    "### <font color='red'> 3.1 ANSWER</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db981a8d",
   "metadata": {},
   "source": [
    "\n",
    "| Attention Type  | Model Size (MB) | Parameter count | Avg. Inference Speed | Throughput |Val Loss | Avg Training time (5 epochs)|\n",
    "|-----------------|-----------------|-----------------|----------------------|------------|----------|-----------------------------|\n",
    "| General         |      23.21  $\\checkmark$    |  6,083,569 $\\checkmark$     |        15.77 ms     | 63.41|   5.636  |     2m 5.2s    $\\checkmark$             |\n",
    "| Additive        |      23.47      |  6,149,617      |      13.12 ms  $\\checkmark$       | 76.22 $\\checkmark$|   5.589 $\\checkmark$ |     2m 17.4s                |\n",
    "| Multiplicative </br>(Extra)  |      23.21      |  6,083,313      |    14.15 ms        | 70.69 |   5.610  |     2m 6.4s                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30007d",
   "metadata": {},
   "source": [
    "Comparison between General and Additive:\n",
    "\n",
    "1. Additive model is ~1% larger in size and parameter.\n",
    "2. Additive is still faster (0.02s vs 0.025s) than General by fraction of sectonds\n",
    "3. Additive has better accuracy (i.e. lower validation loss 5.589 vs 5.639) \n",
    "4. Average training time for additive is higher (2m 17s vs 2m 5s)\n",
    "\n",
    "Since accuracy, inference speed and throughput for Additive is better, Additive wins these performace metrics. \n",
    "\n",
    "Accuracy , inference speed or throughput is related to user experience, Additive model is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb4637",
   "metadata": {},
   "source": [
    "### 3.2) Provide performance plots showing training and validation loss for each type of attention mechanism (General, and Additive). These plots will help in visualizing and comparing the learning curves of different attention models. (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc1fed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for attention_type in attention_models.keys():\n",
    "    tloss = train_losses[attention_type]\n",
    "    vloss = valid_losses[attention_type]\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 3))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(tloss, label = 'train loss', color='blue')\n",
    "    ax.plot(vloss, label = 'valid loss', color='red')\n",
    "    ax.set_title(f'{attention_type} attention')\n",
    "\n",
    "    plt.legend()\n",
    "    ax.set_xlabel('updates')\n",
    "    ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9345f49",
   "metadata": {},
   "source": [
    "### <font color='red'> 3.2 ANSWER</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d07594",
   "metadata": {},
   "source": [
    "Loss Analysis:\n",
    "\n",
    "|Attention Type\t|Final Train Loss|Final Val Loss |Gap (Val - Train)| Observation                |\n",
    "|---------------|----------------|---------------|-----------------|----------------------------|    \n",
    "|General\t    | 4.766\t         | 5.636\t     | 0.87\t           | Moderate overfitting.      |\n",
    "|Additive\t    | 4.701\t         | 5.589\t     | 0.89\t           | Slightly better performance|\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "1. Additive attention performs best — lowest training loss (4.701) and validation loss (5.589)\n",
    "\n",
    "2. All models show overfitting — validation loss is ~0.9 higher than training loss, indicating the models memorize training data better than generalizing\n",
    "\n",
    "3. Similar convergence patterns — all attention mechanisms converge at similar rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5813e",
   "metadata": {},
   "source": [
    "### 3.3) Display the attention maps generated by your model. Attention maps are crucial for understanding how the model focuses on different parts of the input sequence while generating the translation. This visualization will offer insights into the interpretability of your model. (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f450a2",
   "metadata": {},
   "source": [
    "Note: Provide the performance table and graph to Readme.md GitHub as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f51b7",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> 3.3 ANSWER </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4c49f",
   "metadata": {},
   "source": [
    "For 3 Epocs\n",
    "\n",
    "General\n",
    "\n",
    "Epoch: 03 | Time: 2m 6s\n",
    "\n",
    "\tTrain Loss: 4.766 | Train PPL: 117.409\n",
    "\t Val. Loss: 5.636 |  Val. PPL: 280.341\n",
    "\n",
    "Additive\n",
    "\n",
    "Epoch: 03 | Time: 2m 14s\n",
    "\n",
    "\tTrain Loss: 4.701 | Train PPL: 110.076\n",
    "\t Val. Loss: 5.589 |  Val. PPL: 267.469\n",
    "\n",
    "| Attention Type | Training Loss | Training PPL | Validation Loss | Validation PPL |\n",
    "|----------------|---------------|--------------|-----------------|----------------|\n",
    "| General        |   4.766       |   117.409    |      5.636      |    280.341     |\n",
    "| Additive       |   4.701       |   110.076    |      5.589      |    267.469     |\n",
    "\n",
    "Key obserbations:\n",
    "\n",
    "- Losses are still high - PPL (perpexity) of 267-280 means the model is still quite \"confused\". Good translation mode perplexity expected below 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8ae9f",
   "metadata": {},
   "source": [
    "### 3.4) Analyze the results and discuss the effectiveness of the selected attention mechanism in translating between your native language and English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4989378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time (general): 0.02s\n",
      "general: ▁तपाईँ को ▁सन् देश को ▁गर्न ▁चाह नुहुन्छ ▁?\n",
      "Translation time (multiplicative): 0.03s\n",
      "multiplicative: ▁तपाईँ ले ▁गुप्त िक रण ▁गर्न ▁गर्न ▁गर्न ▁अनुमति ▁दिन्छ ▁।\n",
      "Translation time (additive): 0.02s\n",
      "additive: ▁तपाईँ ले ▁अहिले ▁तार िक रण ▁गर्न ▁निश्चित ▁गर्नुहुन्छ ?\n",
      "Translation time (additive): 0.02s\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Can you translate english to Nepali?\"\n",
    "translations = translate_all_models(sample_text)\n",
    "\n",
    "_SELECTED_ATTENTION = \"additive\"\n",
    "\n",
    "nepali_translations, attentions = translate(sample_text, _SELECTED_ATTENTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b2f2f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The following item is due:', 'निम्न वस्तुको म्याद समाप्त हुन्छ:')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = dataset['train'][100]\n",
    "src_text = sample_text['translation']['en']\n",
    "trg_text = sample_text['translation']['ne']\n",
    "\n",
    "src_text, trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a0dd5842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'The', 'following', 'item', 'is', 'due', ':', '<eos>']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens =['<sos>'] + token_transform[_EN_LANGUAGE](src_text) + ['<eos>']\n",
    "\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5c9d27c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '▁निम्न',\n",
       " '▁वस्तु',\n",
       " 'को',\n",
       " '▁म्या',\n",
       " 'द',\n",
       " '▁समाप्त',\n",
       " '▁हुन्छ',\n",
       " ':',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = ['<sos>'] + token_transform[_NE_LANGUAGE](trg_text) + ['<eos>']\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10198d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    # Fix square for nepali letter, let matplotlib find suitable font:\n",
    "    # Warning fixed - IPython/core/pylabtools.py:170: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from font(s) DejaVu Sans.\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Noto Sans Devanagari', 'Mangal', 'DejaVu Sans']\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=10)\n",
    "    \n",
    "    y_ticks =  [''] + translation\n",
    "    x_ticks =  [''] + sentence \n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "36936aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/vc0jrw957pz0rrhc98mw0hjm0000gp/T/ipykernel_16510/201583952.py:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(x_ticks, rotation=45)\n",
      "/var/folders/4t/vc0jrw957pz0rrhc98mw0hjm0000gp/T/ipykernel_16510/201583952.py:19: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels(y_ticks)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbba4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'Jump to page:', 'ne': 'पृष्ठमा जानुहोस्:'}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src2 = dataset['train'][333]\n",
    "src2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "85b91798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<sos>', 'Jump', 'to', 'page', ':', '<eos>'],\n",
       " ['<sos>', '▁पृष्ठ', 'मा', '▁जानु', 'होस्', ':', '<eos>'])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = ['<sos>'] + token_transform[_EN_LANGUAGE](src2['translation']['en']) + ['<eos>']\n",
    "trg_tokens = ['<sos>'] + token_transform[_NE_LANGUAGE](src2['translation']['ne']) + ['<eos>']\n",
    "\n",
    "src_tokens, trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31f4d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time (additive): 0.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/vc0jrw957pz0rrhc98mw0hjm0000gp/T/ipykernel_16510/201583952.py:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(x_ticks, rotation=45)\n",
      "/var/folders/4t/vc0jrw957pz0rrhc98mw0hjm0000gp/T/ipykernel_16510/201583952.py:19: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels(y_ticks)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation, attentions = translate(src2['translation']['en'], _SELECTED_ATTENTION)\n",
    "display_attention(src_tokens, trg_tokens, attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38075a6c",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> 3.4 ANSWER </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84e0fc",
   "metadata": {},
   "source": [
    "Translation 1:\n",
    "\n",
    "> Source text: \"The following item is due .\"\n",
    ">\n",
    ">Target text (Nepali): 'निम्न वस्तुको म्याद समाप्त हुन्छ:'\n",
    "\n",
    "Translation 2:\n",
    "\n",
    "> Source text: 'Jump to page:'\n",
    ">\n",
    "> Target text (Nepali): 'पृष्ठमा जानुहोस्:'\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "1. Translation 1:\n",
    "    - The heatmap (bone color => white to high, black to low) for Translation 1 shows that model could not learn properly. Almost all token attend to wrong source positions. This makes sense from the PPL score - that being very high ~200. \n",
    "    - The translation provided is itself noisy, the word like `due` captured literal meaning `_समाप्त` but didn't get the context. According to context, `due` mapping is semantically wrong.\n",
    "    - Since white or light colored cells is aligned towards center, model seems to have positional bias rather than learned alignment.\n",
    "\n",
    "2. Translation 2:\n",
    "    - Provided translated text is right. \n",
    "    - The model has been able to learn and map `page` to `_पृष्ठ` correctly.\n",
    "\n",
    "\n",
    "In summary, Model did not learn proper attention - unable to capture semantic meaning , shows positional bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37c0ff",
   "metadata": {},
   "source": [
    "Recommendations:\n",
    "\n",
    "1. Train for more epochs (5-10)\n",
    "2. Select larger set of training data (currently 20K, try 50K+)\n",
    "3. The gap between train and validation loss suggests regularization could help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f01fe3",
   "metadata": {},
   "source": [
    "## Task 4. Machine Translation - Web Application Development - Develop a simple web application that showcases the capabilities of your language model in machine translation. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd8b05",
   "metadata": {},
   "source": [
    "1) The application should feature an input box where users can enter a sentence or phrase in a source\n",
    "language.\n",
    "2) Based on the input, the model should generate and display the translated version in a target language.\n",
    "For example, if the input is ”Hello, how are you?” in English, the model might generate\n",
    "”Hola, ¿c´omo est´as?” in Spanish.\n",
    "3) Provide documentation on how the web application interfaces with the language model for machine\n",
    "translation.\n",
    "Note : Choose the most effective attention mechanism based on your experiments in Task 2.\n",
    "As always, the example Dash Project in the GitHub repository contains an example that you can follow\n",
    "(if you use the Dash framework)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf9d84",
   "metadata": {},
   "source": [
    "### Save Model and Vocabularies for Flask App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "903890a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabularies saved to ./../models/vocabs.pt\n",
      "  EN vocab size: 6151\n",
      "  NE vocab size: 4785\n",
      "\n",
      "Model saved to: ./../models/Seq2SeqPackedAttention_additive.pt\n",
      "\n",
      "To run the Flask app:\n"
     ]
    }
   ],
   "source": [
    "# Save vocabularies for Flask app\n",
    "import os\n",
    "\n",
    "save_dir = _MODEL_DIRECTORY\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "vocab_data = {\n",
    "    'en_stoi': vocab_transform[_EN_LANGUAGE].stoi,\n",
    "    'en_itos': vocab_transform[_EN_LANGUAGE].itos,\n",
    "    'ne_stoi': vocab_transform[_NE_LANGUAGE].stoi,\n",
    "    'ne_itos': vocab_transform[_NE_LANGUAGE].itos,\n",
    "}\n",
    "\n",
    "torch.save(vocab_data, os.path.join(save_dir, \"vocabs.pt\"))\n",
    "print(f\"Vocabularies saved to {save_dir}/vocabs.pt\")\n",
    "print(f\"  EN vocab size: {len(vocab_data['en_itos'])}\")\n",
    "print(f\"  NE vocab size: {len(vocab_data['ne_itos'])}\")\n",
    "print(f\"\\nModel saved to: {save_path}\")\n",
    "print(\"\\nTo run the Flask app:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-npl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
